{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Derive plotwise metrics with pyForMetrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, we will derive some LiDAR metrics for forest inventory (FI) plots.\n",
    "\n",
    "First, we ensure that the required packages are installed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyForMetrix in c:\\users\\lukas\\miniconda3\\envs\\fsct\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: shapely in c:\\users\\lukas\\miniconda3\\envs\\fsct\\lib\\site-packages (1.8.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyForMetrix\n",
    "!python -m pip install geopandas wget"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then need to gather some data. In this example, we use data from Germany (Open Geodata Thüringen, ©GDI-Th, [dl-de/by-2-0](http://www.govdata.de/dl-de/by-2-0)). They can be downloaded from the [geodata portal of the State of Thuringia](https://www.geoportal-th.de/de-de/Downloadbereiche/Download-Offene-Geodaten-Th%C3%BCringen) (in German). **Approximate download size: 120 MB**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "import os, wget, zipfile\n",
    "if not os.path.exists('las_623_5718_1_th_2014-2019.laz'):\n",
    "    if not os.path.exists('data_netzkater.zip'):\n",
    "        print('Downloading file')\n",
    "        wget.download('https://geoportal.geoportal-th.de/hoehendaten/LAS/las_2014-2019/las_623_5718_1_th_2014-2019.zip', 'data_netzkater.zip')\n",
    "    print('Unzipping file')\n",
    "    zipfile.ZipFile('data_netzkater.zip').extractall('.')\n",
    "print('Ready!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then use `laspy` to load the file. As the input point cloud is not normalized by height, we first use a utility function in `pyForMetrics.normalizer` to do that for us.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasterizing for point normalization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing LiDAR points: 100%|██████████| 40000/40000 [00:03<00:00, 11261.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "file = laspy.read(r\"las_623_5718_1_th_2014-2019.laz\")\n",
    "points = {\n",
    "    'points': file.xyz,\n",
    "    'classification': file.classification,\n",
    "    'scan_angle_rank': file.scan_angle_rank\n",
    "}\n",
    "\n",
    "from pyForMetrix.normalizer import normalize\n",
    "points = normalize(points, distance=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we load some polygons from a shapefile. These polygons represent circular areas, for which e.g. forest inventories have been carried out, but any valid polygon shape may be used. Our data is stored in a [GeoPackage](https://www.geopackage.org/) file, but any file supported by [GeoPandas](https://geopandas.org/en/stable/) or [Shapely](https://shapely.readthedocs.io/en/stable/manual.html) will work."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            geometry\n",
      "0  POLYGON ((623210.094 5718429.347, 623210.781 5...\n",
      "1  POLYGON ((623257.611 5718187.129, 623258.297 5...\n",
      "2  POLYGON ((623700.325 5718631.002, 623701.012 5...\n",
      "3  POLYGON ((623709.596 5718801.366, 623710.283 5...\n",
      "4  POLYGON ((623910.093 5718108.321, 623910.779 5...\n",
      "5  POLYGON ((623234.432 5718588.122, 623235.119 5...\n",
      "6  POLYGON ((623516.054 5718391.102, 623516.740 5...\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "plots = gpd.GeoDataFrame.from_file(r\"netzkater_polygons.gpkg\")\n",
    "print(plots)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will calculate metrics for each of these plots. In this example, we use a combination of different metrics in the `types` namespace. As we don't have an index file (.lax) for this input file, scanning though all the points may take a minute or two. If you have [LAStools](https://rapidlasso.com/lastools/) installed, you can create an index file by running `lasindex -i las_623_5718_1_th_2014-2019.laz`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning input files to find polygon plots: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.35s/it]\n",
      "Calculating metrics: 100%|██████████| 7/7 [00:00<00:00, 700.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d10  d20  d30  d40  d50  d60  d70  d80  d90  d100  ...       p70       p80  \\\n",
      "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  390.7311  392.3204   \n",
      "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  468.9515  470.5180   \n",
      "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  406.6710  407.7968   \n",
      "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  434.1044  435.8306   \n",
      "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  377.1825  379.0810   \n",
      "5  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  325.9076  326.1004   \n",
      "6  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   0.0  ...  327.1171  327.3150   \n",
      "\n",
      "        p90     p100      h_mean   h_stddev   h_absdev    h_skew  h_kurtosis  \\\n",
      "0  393.7132  400.546  382.338601   9.024213   8.644587  0.153006   -1.736357   \n",
      "1  471.9530  474.233  458.965645  10.989637  10.410608 -0.085498   -1.753655   \n",
      "2  408.8468  413.032  397.055385  10.786964  10.365036 -0.177707   -1.769685   \n",
      "3  438.1616  441.869  421.794961  14.293303  13.655775 -0.162661   -1.759780   \n",
      "4  380.5385  384.530  364.064363  13.554681  12.987975  0.062077   -1.811338   \n",
      "5  326.3062  326.627  325.513633   0.595316   0.509010 -0.084625   -1.069922   \n",
      "6  327.5887  327.990  326.703678   0.645383   0.547947 -0.013708   -0.996035   \n",
      "\n",
      "   h_entropy  \n",
      "0   2.063130  \n",
      "1   2.628478  \n",
      "2   2.532251  \n",
      "3   2.578637  \n",
      "4   2.448916  \n",
      "5   2.963720  \n",
      "6   2.940392  \n",
      "\n",
      "[7 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyForMetrix.metrix import PlotMetrics\n",
    "from pyForMetrix.metricCalculators.types import *\n",
    "\n",
    "pm = PlotMetrics([\"las_623_5718_1_th_2014-2019.laz\"], plots)\n",
    "mc = [MCalc_DensityMetrics(), MCalc_HeightMetrics(), MCalc_VarianceMetrics()]\n",
    "metr = pm.calc_custom_metrics(mc)\n",
    "print(metr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-102.91839999999996\n"
     ]
    }
   ],
   "source": [
    "print(np.min(points['points'][:, 2\n",
    "        ]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
